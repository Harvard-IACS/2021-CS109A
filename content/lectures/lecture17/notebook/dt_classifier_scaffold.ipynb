{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "Classification using Decision Tree\n",
    "\n",
    "## Description :\n",
    "The goal of this exercise is to get comfortable using Decision Trees for classification in sklearn.  Eventually, you will produce a plot similar to the one given below:\n",
    "\n",
    "<img src=\"../fig/fig1.png\" style=\"width: 500px;\">\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- Read the train and test datafile as Pandas data frame.\n",
    "- Use `minority` and `bachelor` as the predictor variables and `won` as the response.\n",
    "- Fit a decision tree of depth 2 and another of depth 10 on the training data.\n",
    "- Call the function `plot_boundary` to visualise the decision boundary of these 2 classifiers.\n",
    "- Increase the number of predictor variables as mentioned in scaffold.\n",
    "- Initialize a decision tree classifier of depth 2, 10 and 15. \n",
    "- Fit the model on the train data.\n",
    "- Compute the train and test accuracy scores for each classifier.\n",
    "- Use the helper code to look at the feature importance of the predictors from the decision tree of depth 15.\n",
    "\n",
    "## Hints: \n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" target=\"_blank\">sklearn.DecisionTreeClassifier()</a>\n",
    "Generates a Logistic Regression classifier\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\" target=\"_blank\">sklearn.score()</a>\n",
    "Accuracy classification score.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit\" target=\"_blank\">classifier.fit()</a>\n",
    "Build a decision tree classifier from the training set (X, y).\n",
    "\n",
    "**Note: This exercise is auto-graded and you can try multiple attempts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import plot_boundary\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file \"election_train.csv\" as a Pandas dataframe\n",
    "elect_train = pd.read_csv(\"election_train.csv\")\n",
    "\n",
    "# Read the data file \"election_test.csv\" as a Pandas dataframe\n",
    "elect_test = pd.read_csv(\"election_test.csv\")\n",
    "\n",
    "# Take a quick look at the train data\n",
    "elect_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the columns minority and bachelor as train data predictors\n",
    "X_train = ___\n",
    "\n",
    "# Set the columns minority and bachelor as test data predictors\n",
    "X_test = ___\n",
    "\n",
    "# Set the column \"won\" as the train response variable\n",
    "y_train = ___\n",
    "\n",
    "# Set the column \"won\" as the test response variable\n",
    "y_test = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree classifier with a depth of 2\n",
    "dt1 = ___\n",
    "\n",
    "# Fit the classifier on the train data\n",
    "___\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 10\n",
    "dt2 = ___\n",
    "\n",
    "# Fit the classifier on the train data\n",
    "___\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function plot_boundary from the helper file to get \n",
    "# the decision boundaries of both the classifiers\n",
    "plot_boundary(elect_train, dt1, dt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of predictor columns\n",
    "pred_cols = ['minority', 'density','hispanic','obesity','female','income','bachelor','inactivity']\n",
    "\n",
    "# Use the columns above as the predictor data from the train data\n",
    "X_train = elect_train[pred_cols]\n",
    "\n",
    "# Use the columns above as the predictor data from the test data\n",
    "X_test = elect_test[pred_cols]\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 2\n",
    "dt1 = ___\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 10\n",
    "dt2 = ___\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 15\n",
    "dt3 = ___\n",
    "\n",
    "# Fit all the classifier on the train data\n",
    "___\n",
    "___\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_accuracy) ###\n",
    "\n",
    "# Compute the train and test accuracy for the first decision tree classifier of depth 2\n",
    "dt1_train_acc = ___\n",
    "dt1_test_acc = ___\n",
    "\n",
    "# Compute the train and test accuracy for the second decision tree classifier of depth 10\n",
    "dt2_train_acc = ___\n",
    "dt2_test_acc = ___\n",
    "\n",
    "# Compute the train and test accuracy for the third decision tree classifier of depth 15\n",
    "dt3_train_acc = ___\n",
    "dt3_test_acc = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code to plot the scores of each classifier as a table\n",
    "pt = PrettyTable()\n",
    "pt.field_names = ['Max Depth', 'Number of Features', 'Train Accuracy', 'Test Accuracy']\n",
    "pt.add_row([2, 2, round(dt1_train_acc, 4), round(dt1_test_acc,4)])\n",
    "pt.add_row([10, 2, round(dt2_train_acc,4), round(dt2_test_acc,4)])\n",
    "pt.add_row([15, len(pred_cols), round(dt3_train_acc,4), round(dt3_test_acc,4)])\n",
    "print(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
