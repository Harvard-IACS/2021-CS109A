{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9: Decision Trees and Bagging\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2021**<br/>\n",
    "**Instructors**: Pavlos Protopapas and Natesh Pillai<br/>\n",
    "**Lab Team**: Marios Mattheakis, Hayden Joy, Chris Gumb, and Eleni Kaxiras<br/>\n",
    "**Authors**: Hayden Joy, and Marios Mattheakis\n",
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will work with a spam email dataset. Our ultimate goal is to be able to build models so that we can predict whether an email is spam or not spam based on word characteristics within each email. We will cover Decision Trees and Bagging methods and allow you to apply it to the homework.\n",
    "\n",
    "Specifically, we will: \n",
    "    \n",
    "    1. Load in the spam dataset and split the data into train and test.\n",
    "    2. Find the optimal depth for the Decision Tree model and evaluate performance.\n",
    "    3. Fit the Bagging model using multiple bootstrapped datasets and do majority voting. \n",
    "    \n",
    "Hopefully after this lab you will be able to answer the following questions: \n",
    " - What are decision tree models?\n",
    " - How do we construct them?\n",
    " - How do we visualize them?\n",
    " - What is bagging?\n",
    " - Why does bagging help with overfitting?\n",
    " - Why does bagging help to built more expressive trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "#### The Idea: Decision Trees are just flowcharts and are interpretable!\n",
    "\n",
    "<img src=\"data/flowchart.png\" alt=\"how to fix anything\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "It turns out that simple flow charts can be formulated as mathematical models for classification and these models have the properties we desire;\n",
    " - interpretable by humans \n",
    " - have sufficiently complex decision boundaries \n",
    " - the decision boundaries are locally linear, each component of the decision boundary is simple to describe mathematically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----------\n",
    "\n",
    "#### Let's review some theory: \n",
    "\n",
    "#### How to build Decision Trees (the Learning Algorithm in words): \n",
    "To learn a decision tree model, we take a greedy approach: \n",
    " 1. Start with an empty decision tree (undivided feature space) \n",
    " 2. Choose the ‘optimal’ predictor on which to split and choose the ‘optimal’ threshold value for splitting by applying a **splitting criterion (1)**\n",
    " 3. Recurse on on each new node until **stopping condition (2)** is met\n",
    " \n",
    "For classification, we label each region in the model with the label of the class to which the majority of the points within the region belong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we need a (1) splitting criterion and a (2) stopping condition:\n",
    "\n",
    "  #### (1) Splitting criterion \n",
    "<img src=\"data/split1.png\" alt=\"split1\" width=\"70%\"/>\n",
    "\n",
    "---\n",
    "<img src=\"data/split2.png\" alt=\"split2\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig/simple_tree.png\" alt=\"tree_adj\" width=\"39%\"/>\n",
    "<img src=\"fig/tree_loss.png\" alt=\"tree_adj\" width=\"39%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Stopping condition\n",
    "\n",
    "If we don’t terminate the decision tree learning algorithm manually, the tree will continue to grow until each region defined by the model possibly contains exactly one training point (and the model attains 100% training accuracy). **Not stopping while building a deeper and deeper tree = 100% training accuracy; What will your test accuracy be? What can we do to fix this?**\n",
    "\n",
    "To prevent the **overfitting** from happening, we could \n",
    "- Stop the algorithm at a particular depth. (=**not too deep**)\n",
    "- Don't split a region if all instances in the region belong to the same class. (=**stop when subtree is pure**)\n",
    "- Don't split a region if the number of instances in the sub-region will fall below pre-defined threshold (min_samples_leaf). (=**not too specific/small subtree**)\n",
    "- Don't use too many splits in the tree (=**not too many splits / not too complex global tree**)\n",
    "- Be content with <100% accuracy training set...\n",
    "\n",
    "-------------\n",
    "\n",
    "#### Done with theory, let's get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "\n",
    "#new model objects\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-------------\n",
    "\n",
    "# Part 1 : Introduction to the Spam Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with a spam email dataset. The dataset has 57 predictors with a response variable called `Spam` that indicates whether an email is spam or not spam. The goal is to be able to create a classifier or method that acts as a spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataframe and Set Column Names\n",
    "spam_df = pd.read_csv('data/spam.csv', header=None)\n",
    "columns = [\"Feature_\"+str(i+1) for i in range(spam_df.shape[1]-1)] + ['Spam']\n",
    "spam_df.columns = columns\n",
    "display(spam_df.head())\n",
    "len(spam_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictors are all continuous. They represent certain features like the frequency of the word `'discount'`. The exact specification and description of each predictor can be found online. We are not so much interested in the exact inference of each predictor so we will omit the exact names of each of the predictors. We are more interested in the predictions of the algorithm so we will not go into detail about the individual features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to description : https://archive.ics.uci.edu/ml/datasets/spambase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the dataset into a 70-30 split by using the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :** While you will use ```train_test_split``` in your homeworks, the code below should help you visualize splitting/masking of a dataframe which will be helpful in general.\n",
    "\n",
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#draw n samples from the uniform distribution\n",
    "uniform_samples = np.random.rand(len(spam_df))\n",
    "\n",
    "#create boolean mask\n",
    "msk = uniform_samples < 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the combined design matrix/ response dataframe with the boolean mask\n",
    "data_train = spam_df[msk]\n",
    "data_test  = spam_df[~msk]\n",
    "\n",
    "#Split predictor and response columns\n",
    "x_train, y_train = data_train.drop(['Spam'], axis=1), data_train['Spam']\n",
    "x_test , y_test  = data_test.drop(['Spam'] , axis=1), data_test['Spam']\n",
    "\n",
    "print(\"Shape of Training Set :\",data_train.shape)\n",
    "print(\"Shape of Testing Set :\" ,data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~msk*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert True ==1\n",
    "# assert False == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the number of spam cases is roughly evenly represented in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Percentage of Spam in Train and Test Set\n",
    "pct_spam_tr = 100*y_train.mean()\n",
    "pct_spam_te = 100*y_test.mean()\n",
    "                                                  \n",
    "print(f\"Percentage of Spam in Training Set \\t : {pct_spam_tr:0.2f}%\")\n",
    "print(f\"Percentage of Spam in Testing Set \\t : {pct_spam_te:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "# Part 2 : Fitting an Optimal Single Decision Tree (by Depth) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit here a single tree to our spam dataset and perform 5-fold cross validation on the training set. For ***each*** decision tree depth, we fit a tree and then compute the 5-fold CV scores. These scores are then averaged and compared across different depths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal depth of trees\n",
    "mean_CV_acc = {}\n",
    "all_CV_acc = {}\n",
    "tree_depth_start, tree_depth_end, steps = 3, 31, 4\n",
    "for i in range(tree_depth_start, tree_depth_end + 1, steps):\n",
    "    \n",
    "    #declare tree model object\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    \n",
    "    #get cv scores\n",
    "    scores = cross_val_score(estimator=model, X=x_train, y=y_train, cv=5, n_jobs=-1)\n",
    "    \n",
    "    all_CV_acc[i] = scores\n",
    "    mean_CV_acc[i] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mean_CV_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dictionary manipulations for our x,y construction for the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(mean_CV_acc.keys())\n",
    "y = list(mean_CV_acc.values())\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(mean_CV_acc.items())\n",
    "x, y = zip(*lists)   \n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "plt.plot(x, y, 'b-', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the optimal depth is found to be a depth of 7. Although, does it makes sense to choose 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if we wanted to get the Confidence Bands of these results, how would we? It's as simple as a combination of getting variance using ```scores.std()``` and ```plt.fill_between()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = np.array([ np.std(scores) for scores in all_CV_acc.values() ])\n",
    "stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9,4))\n",
    "plt.fill_between(x, y + stds, y - stds, alpha=0.2)\n",
    "\n",
    "#Plot\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "plt.plot(x, y, 'b-', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to display it as a boxplot we first construct a dataframe with all the scores and second we use ```sns.boxplot(...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a numpy array with all the CV acc scores\n",
    "cv_scores_df = pd.DataFrame(all_CV_acc.values(), index = all_CV_acc.keys()).T\n",
    "cv_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt\n",
    "trees = pd.melt(cv_scores_df, var_name = \"Max Depth\", value_name = 'CV Accuracy Score')\n",
    "trees.head(10)\n",
    "\n",
    "#this code achieves the same thing without pd.melt:\n",
    "# Making a dataframe\n",
    "# trees = pd.DataFrame({'Max Depth':list(x)*5, 'CV Accuracy Score': list(cv_scores_df.values.T.flatten())})\n",
    "# trees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the boxplot \n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "sns.boxenplot(x=\"Max Depth\", y=\"CV Accuracy Score\", data=trees);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the boxplot without outliers (showfliers = False)\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "sns.boxenplot(x=\"Max Depth\", y=\"CV Accuracy Score\", data=trees, showfliers=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's extract the best_depth value from this dictionary:** \n",
    "\n",
    "We create the new variable ```best_depth```. Can you see why we coded the best depth parameter as we did below? (Hint: Think about reproducibility.)\n",
    "\n",
    "How to sort using your own function with key parameter?\n",
    "If you want your own implementation for sorting, sorted() also accepts a key function as an optional parameter.\n",
    "\n",
    "Based on the results of the key function, you can sort the given iterable.\n",
    "\n",
    "```sorted(iterable, key=len)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do? Is this the result we want?\n",
    "sorted(mean_CV_acc, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "sorted(mean_CV_acc, key=mean_CV_acc.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make best depth a variable\n",
    "best_depth = sorted(mean_CV_acc, key=mean_CV_acc.get, reverse=True)[0]\n",
    "print(\"The best depth was found to be:\", best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaute the performance at the best depth\n",
    "model_tree = DecisionTreeClassifier(max_depth=best_depth)\n",
    "model_tree.fit(x_train, y_train)\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set\n",
    "acc_trees_training = accuracy_score(y_train, model_tree.predict(x_train))\n",
    "acc_trees_testing  = accuracy_score(y_test,  model_tree.predict(x_test))\n",
    "\n",
    "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_training))\n",
    "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Performance by Class (Lookup Confusion Matrix)\n",
    "pd.crosstab(index    = y_test, \n",
    "            columns  = model_tree.predict(x_test), \n",
    "            rownames = ['Actual'],\n",
    "            colnames = ['Predicted'],\n",
    "            margins  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to visualize a Decision Tree with ```pydot```\n",
    "\n",
    "*Question:* Do you think this tree is interpretable? What do you think about a the maximal depth of the tree?\n",
    "\n",
    "- Let's first store the decision tree in a text format: ```decision_tree.dot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa389c8eef43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"results/decision_tree.dot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_tree' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "file_name = \"results/decision_tree.dot\"\n",
    "tree.export_graphviz(model_tree, out_file = file_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's look at the resulting text ```decision_tree.dot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head results/decision_tree.dot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's convert our (hard to read) written decision tree (```decision_tree.dot```) into an intuitive image file format: ```image_tree.png```\n",
    "- <span style=\"color:red\">**NOTE:**</span> You might need to install the ```pydot``` package by typing the following command in your terminal: ```pip install pydot``` or you can install from within the jupyter notebook by running the following cell: ```! pip install pydot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install pydot -y\n",
    "#! conda install graphiv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "(graph,) = pydot.graph_from_dot_file(file_name)\n",
    "graph.write_png('results/image_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's display the ```image_tree.png``` in markdown:\n",
    "\n",
    "Markdown: ```![title](results/image_tree.png)```. The result: \n",
    "\n",
    "![title](results/image_tree.png)\n",
    "\n",
    "*Repost Question:* Do you think this tree is interpretable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <strong>🏋🏻‍♂️ TEAM ACTIVITY 1:</strong> Implimenting Decision Trees </div>  \n",
    "\n",
    "\n",
    "*Let's try out decision tree models on a cancer dataset. Click <a href = \"https://towardsdatascience.com/building-a-simple-machine-learning-model-on-breast-cancer-data-eca4b3b99fa3\">here </a> for another example with this dataset and more information.\n",
    "\n",
    "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
    "\n",
    "Features:\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry \n",
    "- fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "Target:\n",
    "    2) Diagnosis (M = malignant, B = benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix shape (569, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture error</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>mean radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.565265</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.316862</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>0.660820</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>0.907083</td>\n",
       "      <td>1.097064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.876244</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>-0.692926</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>0.260162</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>-0.099444</td>\n",
       "      <td>1.829821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.780083</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.814974</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>1.424827</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>0.293559</td>\n",
       "      <td>1.579888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.110409</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>2.744280</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.115007</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>2.047511</td>\n",
       "      <td>-0.768909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   texture error  worst texture  worst symmetry  compactness error  worst radius  worst compactness  concave points error  worst fractal dimension  fractal dimension error  mean radius\n",
       "0      -0.565265      -1.359293        2.750622           1.316862      1.886690           2.616665              0.660820                 1.937015                 0.907083     1.097064\n",
       "1      -0.876244      -0.369203       -0.243890          -0.692926      1.805927          -0.430444              0.260162                 0.281190                -0.099444     1.829821\n",
       "2      -0.780083      -0.023974        1.152255           0.814974      1.511870           1.082932              1.424827                 0.201391                 0.293559     1.579888\n",
       "3      -0.110409       0.133984        6.046041           2.744280     -0.281464           3.893397              1.115007                 4.935010                 2.047511    -0.768909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target classes    {1: 'Benign', 0: 'Malignant'}\n",
      "There are 357 Benign cases and 212 Malignant cases in the target\n"
     ]
    }
   ],
   "source": [
    "from functions import tree_pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "get_tree_scores = tree_pd.get_tree_scores\n",
    "cancer_scaled, target = tree_pd.load_cancer_dataset(10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your tasks are as follows:\n",
    "\n",
    "0) Perform a manual 80-20 train-test split\n",
    "\n",
    "1) -4) see below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Train Test split\n",
    "np.random.seed(40)\n",
    "\n",
    "#test_proportion\n",
    "test_prop = 0.2\n",
    "\n",
    "#sample from a random uniform distribution\n",
    "uniform_samples = np.random.uniform(0, 1, ...)\n",
    "#create a boolean vector mask\n",
    "msk = ...\n",
    " \n",
    "#Split predictor and response columns\n",
    "x_train, y_train = ...\n",
    "x_test , y_test  = ...\n",
    "\n",
    "print(\"Shape of Training Set :\", x_train.shape)\n",
    "print(\"Shape of Testing Set :\" , x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'solutions/sol_tr_te_split.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use the `get_tree_scores` function to assign a dataframe of cross-validation scores for different depths of a `DecisionTreeClassifier`. Specifically feed the function a class instance with `random_state=42`.  This function takes four arguments (x_train, y_train, model, tree_depth_range). This function returns a dictionary of scores.\n",
    "\n",
    "2) use `pd.DataFrame` and `pd.melt` to assign a dataframe `cv_acc_df`. This dataframe should have two columns: `depth`  and `cv_acc_score`. Hint: check out the `var_name` and `value_name` arguments of `pd.melt`.\n",
    "\n",
    "3) Visualize the mean cross validation accuracy scores using `sns.boxenplot` or another function of your choice similar to `sns.catplot`\n",
    "\n",
    "4) Use pandas groupby function to to get the mean cross-validation accuracy for specific depths. Assign to a new dataframe `cv_acc_mean`.\n",
    "\n",
    "5) Visualize the mean cross validation accuracy scores using `sns.lineplot` in combination with `cv_acc_mean`. Discuss what you see with your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'solutions/sol1.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### once you have successfully completed the code above, this code should run without a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best depth 2\n",
      "Testing set accuracy 0.9174\n"
     ]
    }
   ],
   "source": [
    "max_idx = cv_acc_mean[\"cv_acc_score\"].idxmax()\n",
    "best_depth = cv_acc_mean[\"depth\"][max_idx]\n",
    "print(\"best depth {:}\".format(best_depth))\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=best_depth)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "cancer_tree_accuracy = model.score(x_test, y_test)\n",
    "\n",
    "print(\"Testing set accuracy {:.4f}\".format(cancer_tree_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now answer the following questions:\n",
    "\n",
    "$\\bullet$ Why is the best depth the value that it is?\n",
    "\n",
    "$\\bullet$ Why might the deeper trees be over or under fitting on this particular dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO\n",
    "# tree.export_graphviz(model, \"example_tree.dot\")\n",
    "# import pydot\n",
    "# (graph,) = pydot.graph_from_dot_file(\"example_tree.dot\")\n",
    "# graph.write_png('results/small_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try feeding the get_tree_pd an additional \"bootstraps\" argument and comment on what happens to the validation accuracy.\n",
    "\n",
    "- Let's display the ```image_tree.png``` in markdown:\n",
    "\n",
    "Markdown: ```![title](results/small_tree.png)```. The result: \n",
    "\n",
    "![title](results/small_tree2.png)\n",
    "\n",
    "*Repost Question:* Do you think this tree is interpretable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'solutions/sol1_boot.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------\n",
    "\n",
    "\n",
    "# Part 3: Bagging and Voting\n",
    "\n",
    "*QUESTION:* Where does the word *\"Bagging\"* come from?\n",
    "\n",
    "#### Some Theory: What is bagging?\n",
    "  1. Bootstrapping: resample with replacements to get different datasets and built different models.\n",
    "  2. Do something smart to combine the different models.\n",
    "  \n",
    "One way to adjust for the high variance of the output of an experiment is to perform the experiment multiple times and then average the results. \n",
    "\n",
    " 1. **Bootstrap:** we generate multiple samples of training data, via bootstrapping. We train a full decision tree on each sample of data. \n",
    " 2. **AGgregatiING** for a given input, we output the averaged outputs of all the models for that input. \n",
    " \n",
    "This method is called **Bagging: B** ootstrap + **AGG**regat**ING**. \n",
    "\n",
    "-----------\n",
    "\n",
    "Let's bootstrap our training dataset to create multiple datasets and fit Decision Tree models to each.\n",
    "\n",
    "(Resampling: we showed live that different samples give different results for things like sums, varying more when the things we sum over have high variance themselves.)\n",
    "\n",
    "\n",
    "<img src=\"fig/bagging_array.png\" alt=\"tree_adj\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stat on all data\n",
    "data_train.mean(axis=0).to_frame('mean').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data_train.drop(['Spam'], axis=1), data_train['Spam']\n",
    "x_test , y_test  = data_test.drop(['Spam'] , axis=1), data_test['Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(frac=1., replace=True).mean(axis=0).to_frame('mean').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually fit the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 100 # we tried a variety of numbers here\n",
    "choosen_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model\n",
    "np.random.seed(0)\n",
    "model = DecisionTreeClassifier(max_depth=choosen_depth)\n",
    "\n",
    "#Initializing variables\n",
    "predictions_train = np.zeros( shape = (data_train.shape[0], n_trees))\n",
    "predictions_test  = np.zeros( shape = (data_test.shape[0],  n_trees))\n",
    "\n",
    "#Conduct bootstraping iterations\n",
    "for i in range(n_trees):\n",
    "    temp = data_train.sample(frac=1, replace=True)\n",
    "    boot_y = temp['Spam']\n",
    "    boot_X = temp.drop(['Spam'], axis=1)\n",
    "    \n",
    "    model.fit(boot_X, boot_y)  \n",
    "    predictions_train[:,i] = model.predict(x_train)   \n",
    "    predictions_test[:,i] = model.predict(x_test)\n",
    "    \n",
    "#Make Predictions Dataframe\n",
    "columns = [\"Bootstrap-Model_\"+str(i+1) for i in range(n_trees)]\n",
    "predictions_train = pd.DataFrame(predictions_train, columns=columns)\n",
    "predictions_test = pd.DataFrame(predictions_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['Spam'].values\n",
    "y_test = data_test['Spam'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example Bolean for locating the Non Spam\n",
    "y == 0\n",
    "## Example Bolean for locating the Spam\n",
    "y == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_avg = 100\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 7))\n",
    "for (ax, label, predictions, y) in [\n",
    "    (axs[0], 'Training Set', predictions_train, y_train), \n",
    "    (axs[1], 'Test Set' , predictions_test , y_test ) ]:\n",
    "    \n",
    "    # Take the average\n",
    "    mean_predictions = predictions.iloc[:,:num_to_avg].mean(axis=1)\n",
    "    \n",
    "    # Plot the Spam\n",
    "    mean_predictions[y == 1].hist(density=True, histtype='step', \n",
    "                                  range=[0,1], label='Spam', lw=2, ax=ax)\n",
    "    \n",
    "    # Plot the non Spam\n",
    "    mean_predictions[y == 0].hist(density=True, histtype='step', \n",
    "                                  range=[0,1], label='Not-Spam', lw=2, ax=ax)\n",
    "    ax.legend(loc='upper center');\n",
    "    ax.set_xlabel(\"Mean of ensemble predictions (0.5=50 True - 50 False)\")\n",
    "    ax.set_title(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now get final predictions: majority voting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ensemble the prediction of each bagged decision tree model\n",
    "def get_prediction(df):\n",
    "    return np.mean(df, axis=1)>0.5\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set\n",
    "acc_bagging_training = 100*accuracy_score(y_train, get_prediction(predictions_train))\n",
    "acc_bagging_testing  = 100*accuracy_score(y_test, get_prediction(predictions_test))\n",
    "\n",
    "print(\"Bagging: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_bagging_training))\n",
    "print(\"Bagging: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format( acc_bagging_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count in the above code can be use to define the number of models the voting in the dataframe should be based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Performance by Class (Lookup Confusion Matrix)\n",
    "pd.crosstab(np.array(y_test), model.predict(x_test), margins=True, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Food for Thought :** Are these bagging models independent of each other, can they be trained in a parallel fashion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ensemble: a group of items viewed as a whole rather than individually\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "### Let's talk about decision trees and bagging in the context of bias and variance.\n",
    "<img src=\"fig/bias_variance.png\" alt=\"split2\" width=\"40%\"/>\n",
    "<img src=\"fig/fitting.png\" alt=\"split2\" width=\"40%\"/>\n",
    "\n",
    "#### When is a decision tree underfit? When is a decision tree overfit? Let's think about this in the concept of tree depth.\n",
    "\n",
    "#### Bagging enjoys the benefits of \n",
    "- High expressiveness (by using larger trees it is able to approximate complex functions and decision boundaries).\n",
    "- Low _ _ _  by averaging the prediction of all the models thus reducing the _ _ _  in the final prediction.\n",
    "\n",
    "#### What is the weakness of bagging?\n",
    "- In practice, the ensemble of trees tend to be **highly ___**\n",
    "- When could my bagging model be underfit? In what way does this apply to other ensemble methods?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Initial Questions:\n",
    "\n",
    "- What are decision tree models?\n",
    "- How do we construct them?\n",
    "- How do we vizualize them?\n",
    "- What is the idea of bagging?\n",
    "- Why does bagging help with overfitting?\n",
    "- Why does bagging help to built more expressive trees?\n",
    "\n",
    "#### End of Standard Lab. What about next week? \n",
    "\n",
    "**Gradient Boosting etc.. building upon decision trees. Why should we care?** \n",
    "\n",
    "<img src=\"data/kaggle.png\" alt=\"tree_adj\" width=\"100%\"/>\n",
    "\n",
    "\n",
    "----------\n",
    "<img src=\"fig/trees_adj2.png\" alt=\"tree_adj\" width=\"100%\"/>\n",
    "\n",
    "[Source Medion: \"XGBoost Algorithm: Long May She Reign!\"](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>🏋🏻‍♂️ TEAM ACTIVITY 2:</strong> Bagging Regressor </div>  \n",
    "\n",
    "*Let's try to improve our accuracy scores on the cancer dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Train Test split\n",
    "np.random.seed(40)\n",
    "\n",
    "#test_proportion\n",
    "test_prop = 0.2\n",
    "msk = np.random.uniform(0, 1, len(cancer_scaled)) > test_prop\n",
    "\n",
    "#Split predictor and response columns\n",
    "x_train, y_train = cancer_scaled[msk], target[msk]\n",
    "x_test , y_test  = cancer_scaled[~msk], target[~msk]\n",
    "\n",
    "print(\"Shape of Training Set :\", x_train.shape)\n",
    "print(\"Shape of Testing Set :\" , x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your tasks:\n",
    "1) Complete the `get_bagging_scores` function  below.\n",
    "\n",
    "2) Using `get_bagging_scores` assign a dataframe `bagging_val_acc` using a class instance of `BaggingClassifier`. Try playing with different depths by feeding this object the argument `base_estimator = DecisionTreeClassifier(max_depth = DEPTH)` at initialization. The BaggingClassifier by default takes a `DecisionTreeClassifier`, but it can take other models as well. Try playing with different depths!\n",
    "\n",
    "3) Use pandas groupby function to to get the mean cross-validation accuracy for specific numbers of estimators. Assign to a new dataframe `bagging_mean_acc`.\n",
    "\n",
    "4) Visualize the mean cross validation accuracy scores by running the cell provided. Answer the subsequent questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(BaggingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bagging_scores(x_train, y_train, model, bootstrap_range):\n",
    "    \"\"\"\n",
    "    This function will take a model and a range of values and return a dataframe with columns: [\"depth\", \"cross_val_acc\"]\n",
    "    \n",
    "    Arguments:\n",
    "        model: the model to be run. Specifically this should be a class instance such as\n",
    "            DecisionTreeClassifier().\n",
    "        tree_depth_range: the range of values over which the tree depths should be saved.\n",
    "        \n",
    "    \"\"\"\n",
    "    #write an assert statement that enforces that the model entered is a BaggingClassifier\n",
    "    assert ...\n",
    "\n",
    "    #declare dictionaries\n",
    "    mean_CV_acc = {}\n",
    "    all_CV_acc = {}\n",
    "    \n",
    "    #find and store cross_validated scores\n",
    "    for n_estimators in list(bootstrap_range):\n",
    "        \n",
    "        #modify the bagging ensemble models n_estimators (the number of trees it will fit)\n",
    "        model.n_estimators = ...\n",
    "\n",
    "        score = cross_val_score(estimator= ..., \n",
    "                                X = ..., \n",
    "                                y = ..., \n",
    "                                n_jobs = -1,\n",
    "                                cv= ...)\n",
    "        mean_CV_acc[n_estimators] = score.mean() \n",
    "    \n",
    "    #make a dataframe from the dictionary:\n",
    "    cv_acc_pd = pd.melt(pd.DataFrame(all_CV_acc))\n",
    "    cv_acc_pd.columns = [\"n_estimators\", \"cv_acc_score\"]\n",
    "    return cv_acc_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can adjust the ensemble depth. Try to play with different depths!\n",
    "DEPTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here: call the repaired get_bagging_scores function.\n",
    "bagging_val_acc = get_bagging_df(x_train, \n",
    "                                 y_train, \n",
    "                                 model = ..., \n",
    "                                 bootstrap_range = ...,\n",
    "                                 cv_samples = ...\n",
    "                                 )\n",
    "\n",
    "bagging_mean_acc  = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'solutions/sol2_bagging.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this code when you are finished with the first exercise to compare bagging and the simple decision tree. Final Questions lie below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add a decision tree classifier for comparison.\n",
    "tree_val_acc = get_tree_scores(x_train, \n",
    "                           y_train, \n",
    "                           DecisionTreeClassifier(), \n",
    "                           tree_depth_range = range(1, 10))\n",
    "\n",
    "tree_val_acc = pd.melt(pd.DataFrame(tree_val_acc), var_name = \"depth\", value_name = 'cv_acc_score')\n",
    "\n",
    "tree_mean_acc  = tree_val_acc.groupby(\"depth\").mean()\n",
    "best_tree_depth  = tree_mean_acc.index[tree_mean_acc.idxmax()][0]\n",
    "\n",
    "### Make the plot\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.title('Variation of Accuracy on Validation set with n_estimators - Bagging Classifier')\n",
    "sns.lineplot(x = \"n_estimators\", y = \"cv_acc_score\", data = bagging_val_acc,  \n",
    "             label = \"Ensemble\");\n",
    "plt.axhline(tree_val_acc[\"cv_acc_score\"].mean(), linestyle = '--', color = \"red\", label = \"simple decision tree\");\n",
    "\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"validation set accuracy score\")\n",
    "\n",
    "max_idx = tree_mean_acc[\"cv_acc_score\"].idxmax()\n",
    "\n",
    "best_tree_model = DecisionTreeClassifier(max_depth=best_depth)\n",
    "best_tree_model.fit(x_train, y_train)\n",
    "tree_test_accuracy = best_tree_model.score(x_test, y_test.reshape(-1,))\n",
    "\n",
    "max_idx = bagging_mean_acc[\"cv_acc_score\"].idxmax()\n",
    "best_n_estimators = bagging_mean_acc.index[max_idx]\n",
    "\n",
    "best_ensemble_model = BaggingClassifier(n_estimators=best_n_estimators, random_state = 42)\n",
    "best_ensemble_model.fit(x_train, y_train.reshape(-1,))\n",
    "ensemble_accuracy = best_ensemble_model.score(x_test, y_test.reshape(-1,))\n",
    "\n",
    "print(\"Decision Tree max depth {:}\".format(best_depth))\n",
    "plt.legend()\n",
    "\n",
    "print(\"Best Decision Tree test set accuracy:  {:0.2f}%\".format(tree_test_accuracy*100))\n",
    "print(\"Best Ensemble test set accuracy:  {:0.2f}%\".format(ensemble_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\bullet$ Why doesn't the bagging accuracy score deteriorate in the same way that the decision tree does for deeper trees?\n",
    "\n",
    "$\\bullet$ Does bagging reduce the variance or the bias of our error? How?\n",
    "\n",
    "$\\bullet$ Bonus question: How do random forests differ from Bagging?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {},
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
