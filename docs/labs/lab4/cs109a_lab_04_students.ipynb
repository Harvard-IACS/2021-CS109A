{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \u003cimg style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"\u003e CS109A Introduction to Data Science "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Lab 4: Multiple Regression and Feature engineering \n",
                "\n",
                "**Harvard University**\u003cbr/\u003e\n",
                "**Fall 2021**\u003cbr/\u003e\n",
                "**Instructors**: Pavlos Protopapas and Natesh Pillai\u003cbr/\u003e\n",
                "**Lab Team**: Marios Mattheakis, Hayden Joy, Chris Gumb, and Eleni Kaxiras\u003cbr/\u003e\n",
                "**Authors**: Eleni Kaxiras, Rahul Dave, David Sondak, Will Claybaugh, and Pavlos Protopapas\n",
                "\u003chr style='height:2px'\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
                "import requests\n",
                "from IPython.core.display import HTML\n",
                "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
                "HTML(styles)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Learning Objectives\n",
                "After this lab, you should be able to\n",
                " - Implement multiple regression models with `sklearn`.\n",
                " - Work with categorical variables including transforming them.\n",
                " - Incorporate pipelines into your workflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# from sklearn import preprocessing\n",
                "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
                "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
                "from sklearn.metrics import r2_score, mean_squared_error \n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from pandas.api.types import CategoricalDtype \n",
                "from sklearn.compose import make_column_transformer, TransformedTargetRegressor\n",
                "from sklearn.compose import ColumnTransformer\n",
                "\n",
                "from sklearn.pipeline import Pipeline, make_pipeline\n",
                "from sklearn.linear_model import Ridge\n",
                "from sklearn.impute import SimpleImputer\n",
                "from pandas.plotting import scatter_matrix\n",
                "\n",
                "import seaborn as sns\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca class=\"anchor\" id=\"soccer\"\u003e\u003c/a\u003e\n",
                "## 1 - Exploring the Football data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Introduction\n",
                "\n",
                "The data imported below were scraped by [Shubham Maurya](https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data) and record various facts about players in the English Premier League. \n",
                "#### Our goal is to fit models that predict the players' market value (what the player could earn when hired by a new team).\n",
                "\n",
                "There are all sorts of questions we could answer, for example is there a relationship between a player‚Äôs popularity and his market value?  Or we could make interesting observations about players in the top 6 teams.\n",
                "\n",
                "The data were scraped by [Shubham Maurya](https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data) from a variety of sources, including *transfermrkt.com* and *Fantasy Premier League (FPL)*. They record various facts about players in the English Premier League. \n",
                "\n",
                "#### Data description\n",
                "\n",
                "`name`: Name of the player  \n",
                "`club`: Club of the player  \n",
                "`age` : Age of the player  \n",
                "`position` : The usual position on the pitch  \n",
                "`position_cat` :  1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers   \n",
                "`page_views` : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017  \n",
                "`fpl_points` : FPL points accumulated over the previous season  \n",
                "`region`: 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World  \n",
                "`nationality`: Player's nationality \u003cBR\u003e\n",
                "`new_signing`: Whether a new signing for 2017/18 (till 20th July)  \n",
                "`new_foreign`: Whether a new signing from a different league, for 2017/18 (till 20th July)  \n",
                "`club_id`: a numerical version of the Club feature  \n",
                "\n",
                "**Our return variable**\n",
                "\n",
                "`market_value`: As on transfermrkt.com on July 20th, 2017 "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Import the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "league_df = pd.read_csv(\"league_data.csv\")\n",
                "league_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df.isnull().sum()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### We have not talked about handling missing values so we will just drop this here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df = league_df.dropna()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "response = 'market_value'\n",
                "y = league_df[response]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df.describe(include=\"all\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv class=\"alert alert-success\"\u003e\n",
                "    \u003cstrong\u003eüèãüèª‚Äç‚ôÇÔ∏è TEAM ACTIVITY 1:\u003c/strong\u003e Let's start with some feature engineering.\u003c/div\u003e  \n",
                "    \n",
                "1. The people that hired us to predict on this data want to know if being in a big club affects the market value of a player. So we need to create a new binary categorical variable named `big_clubs` with values $0$ or $1$ designating if a club belongs to the Top 6 clubs:\n",
                "```\n",
                "big_clubs = ['Arsenal', 'Chelsea', 'Liverpool', 'Manchester+City',\n",
                "        'Manchester+United', 'Tottenham']\n",
                "```\n",
                "1. They also want to look at players in age groups and not just by age. Put the `age` feature in bins according to the values below, and name the variable `age_cat`:\n",
                "\u003cBR\u003e\n",
                "![age_cats](age_cats.png)\n",
                "\u003cBR\u003e\n",
                "`pandas` has the [`.cut()`](#https://pandas.pydata.org/docs/reference/api/pandas.cut.html) method that breaks a variable into `bins` with `labels`\n",
                "```\n",
                "age_bins = [___]\n",
                "age_labels = [___]\n",
                "league_df['age_cat'] = pd.cut(x=league_df['age'],\\\n",
                "                                 bins=age_bins, \n",
                "                                 labels=age_labels) \n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. your code here\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# check\n",
                "list(league_df[['club', 'big_club']].groupby(['big_club']).apply(np.unique))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Applying functions to pandas DataFrames and Series\n",
                "A simpler but less generic way to do the previous exercise would be\n",
                "```\n",
                "league_df['big_club2'] = league_df.apply(lambda row: 1 if row['club'] in big_clubs else 0, axis=1)\n",
                "```\n",
                "If the function to create the new column is simple, there is a more direct way to create the new column (feature), e.g.:\n",
                "\n",
                "```\n",
                "df['new_column'] = df['column']**2\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. your code here\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# check\n",
                "list(league_df[['age_cat', 'age', ]].sort_values(by='age_cat').groupby(['age_cat']).apply(np.unique))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Looking at data types more closely"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "league_df.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# let's see what features we want to use in the model\n",
                "categorical_cols = ['position_cat', 'new_signing', 'big_club', 'age_cat', 'region'] # non-ordinal\n",
                "numerical_cols = ['age', 'page_views', 'fpl_points']\n",
                "ordinal_cols = [] # we do not have any"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# cast categorical variables as pandas type `category`\n",
                "cat_type = CategoricalDtype(ordered=False)\n",
                "for var in categorical_cols:\n",
                "    league_df[var] = league_df[var].astype(cat_type)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "league_df[categorical_cols+numerical_cols].dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Shape of things\n",
                "league_df.age.values.reshape(-1,1).shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Stratified train/test split\n",
                "\n",
                "We want to split before we do any EDA since, ideally, we do not want our test set to influence our design decisions. Also, to make sure that the training and test data have appropriate representation of each region; it would be bad for the training data to entirely miss a region. This is especially important because some regions are rather rare.\n",
                "```\n",
                "train and test subsets = sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)[source]\n",
                "```\n",
                "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv class=\"alert alert-success\"\u003e\n",
                "    \u003cstrong\u003eüèãüèª‚Äç‚ôÇÔ∏è TEAM ACTIVITY 2:\u003c/strong\u003e Practice stratified train-test split. Stratify by `region`.\u003c/div\u003e  \n",
                "    \n",
                "Use the `train_test_split` function and its `stratify` argument to split the data, keeping equal representation of each region.\u003cbr\u003eNote: This will not work if the dataset contains missing data.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code here\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check\n",
                "train_data.shape, test_data.shape, y_train.shape, y_test.shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we won't be peeking at the test set, let's explore and look for patterns! We'll practice a number of useful pandas and numpy functions along the way. \n",
                "\n",
                "We notice that our dataset contains columns with different data types. We need to apply a specific preprocessing for each one of them. Categorical variables that are ordinal need to be coded as integers, while the rest of them need to be one-hot-encoded. We can do this sequentially or better use sklearn's `pipeline` structure. Our pipeline could conveniently include any standardization/normalisation of numerical values. For now we will let them as they are."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.pairplot(train_data[['age', 'page_views', 'market_value']], \\\n",
                "                                  kind='reg', diag_kind='hist');"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data.columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data[['club','club_id']].\\\n",
                "                                groupby(['club_id']).agg({'club' : np.unique,\n",
                "                                                        })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data.groupby('position').agg({\n",
                "                                'market_value': np.mean,\n",
                "                                'page_views': np.median,\n",
                "                                'fpl_points': np.max\n",
                "})"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca class=\"anchor\" id=\"pipe\"\u003e\u003c/a\u003e\n",
                "## 2 - Transform categorical variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_cols, numerical_cols"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train = train_data[categorical_cols+numerical_cols].copy()\n",
                "X_test = test_data[categorical_cols+numerical_cols].copy()\n",
                "\n",
                "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Using sklearn `OneHotEncoder()`\n",
                "\n",
                "By default, keeps all one-hot created columns. Fine-grained drop mechanism, can drop only binary variables, or the first in the list of categories, or even a specific one ($cats[i]$).\n",
                "\n",
                "```\n",
                "drop{‚Äòfirst‚Äô, ‚Äòif_binary‚Äô} or a array-like of shape (n_features,), default=None\n",
                "```\n",
                "\n",
                "It also has a mechanism for handling the presence of unknown categories in the test set. \n",
                "```\n",
                "handle_unknown{‚Äòerror‚Äô, ‚Äòignore‚Äô}, default=‚Äôerror‚Äô\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "oh = OneHotEncoder(drop='if_binary', sparse=False, handle_unknown='error') \n",
                "oh_train = oh.fit_transform(train_data[categorical_cols])\n",
                "oh_train[:10]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "list(zip(categorical_cols, oh.categories_))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "oh_train.shape, train_data[categorical_cols].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "oh_test = oh.transform(test_data[categorical_cols])\n",
                "oh_test.shape, test_data[categorical_cols].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# remember these are \"views\" of the dataframe\n",
                "# the dataframe remains unchanged\n",
                "train_data[categorical_cols].head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data[numerical_cols].values.shape, oh_train.shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Using pandas `get_dummies()`\n",
                "\n",
                "By default keeps all $k$ dummies out of $k$ categorical levels. Can be made to remove the first level, so that we have $k-1 dummies$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "dummies_train = pd.get_dummies(train_data[categorical_cols]) #drop_first=True\n",
                "dummies_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# transform the test set\n",
                "dummies_test = pd.get_dummies(test_data[categorical_cols]) "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Note**: if the test dataset has a category that does not exist in the training set, this will throw an error."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.max_columns', None)\n",
                "# create the design matrix for the train set\n",
                "design_train_df = pd.concat([train_data[numerical_cols], dummies_train], axis=1)\n",
                "design_train_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for the test set\n",
                "design_test_df = pd.concat([test_data[numerical_cols], dummies_test], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "design_train_df.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# the dataframe remains unchanged\n",
                "train_data[categorical_cols].head(5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "list(zip(categorical_cols, oh.categories_))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Now, let's run the model using our design matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "#create linear model\n",
                "regression = LinearRegression()\n",
                "\n",
                "#fit linear model\n",
                "regression.fit(design_train_df, y_train)\n",
                "\n",
                "y_pred = regression.predict(design_test_df)\n",
                "\n",
                "r2_train = regression.score(design_train_df, y_train)\n",
                "r2_test = regression.score(design_test_df, y_test)\n",
                "print(f'R^2 train = {r2_train:.5}')\n",
                "print(f'R^2 test = {r2_test:.5}')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca class=\"anchor\" id=\"pipes\"\u003e\u003c/a\u003e\n",
                "## 3 - Using Transformation Pipelines"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There could be many transformations that need to be executed sequentialy in order to construct the design matrix. As we saw, it is possible to handcraft the design matrix ourselves by transforming individual columns, it is more efficient and error-free to create an sklearn `pipeline` to do this for you. Sklearn can work directly with $numpy$ arrays or $DataFrames$. \n",
                "\n",
                "When using the latter, `sklearn.compose.ColumnTransformer` is useful, as it applies transformers to columns of an array or pandas DataFrame. This estimator allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form the design matrix.\n",
                "\n",
                "#### Making a pipeline\n",
                "\n",
                "```\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "my_pipeline = Pipeline([\n",
                "        ('imputer', Imputer(strategy='median')),      # we will be using later\n",
                "        ('std_scaler', StandardScaler()),             # optional\n",
                "        ('selector', ColumnTransformer())             # for one-hot encoding\n",
                "        ('regressor', lr)                             # actual regressor model\n",
                "])\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# transform categoricals\n",
                "categorical_encoder = OneHotEncoder(drop='if_binary', handle_unknown='error') #handle_unknown='ignore'\n",
                "\n",
                "# transform numericals\n",
                "numerical_pipe = Pipeline([\n",
                "                    ('imputer', SimpleImputer(strategy='mean')),     # for later\n",
                "                    #('stdscaler', StandardScaler())                 # for later\n",
                "])\n",
                "\n",
                "# bring all transformations together\n",
                "preprocessor = ColumnTransformer([\n",
                "               ('cat', categorical_encoder, categorical_cols),\n",
                "               ('num', numerical_pipe, numerical_cols)\n",
                "])\n",
                "\n",
                "# add a regressor\n",
                "lr = LinearRegression()\n",
                "\n",
                "model = Pipeline([\n",
                "            ('preprocessor', preprocessor),\n",
                "            ('regressor', lr)\n",
                "])\n",
                "\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "ohe = (model.named_steps['preprocessor'].named_transformers_['cat'])\n",
                "feature_names = ohe.get_feature_names(input_features=categorical_cols)\n",
                "feature_names = np.r_[feature_names, numerical_cols]\n",
                "feature_names = list(feature_names)\n",
                "feature_names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f'LR train R^2: {model.score(X_train, y_train):.3f}')\n",
                "print(f'LR test R^2: {model.score(X_test, y_test):.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# grab the linear regressor\n",
                "linear_regressor = model.named_steps['regressor']\n",
                "linear_regressor.coef_.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.DataFrame(zip(feature_names+numerical_cols, linear_regressor.coef_), columns=['feature', 'coeff'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### A different way to construct the pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "preprocessor = make_column_transformer(\n",
                "         (OneHotEncoder(drop='if_binary', handle_unknown='error'), categorical_cols),\n",
                "         #(StandardScaler(), numerical_columns),\n",
                "         (SimpleImputer(strategy='mean'), numerical_cols),\n",
                "         remainder='passthrough'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = make_pipeline(\n",
                "    preprocessor,\n",
                "    LinearRegression()\n",
                ")\n",
                "\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_names = (model.named_steps['columntransformer']\n",
                "                      .named_transformers_['onehotencoder']\n",
                "                      .get_feature_names(input_features=categorical_cols))\n",
                "feature_names = np.concatenate(\n",
                "    [feature_names, numerical_cols])\n",
                "\n",
                "coefs = pd.DataFrame(\n",
                "    model.named_steps['linearregression'].coef_,\n",
                "    columns=['Coefficients'], index=feature_names\n",
                ")\n",
                "\n",
                "coefs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f'LR train R^2: {model.score(X_train, y_train):.3f}')\n",
                "print(f'LR test R^2: {model.score(X_test, y_test):.3f}')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca class=\"anchor\" id=\"linear\"\u003e\u003c/a\u003e\n",
                "## 4 - Feature Engineering"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv class=\"alert alert-success\"\u003e\n",
                "    \u003cstrong\u003eüèãüèª‚Äç‚ôÇÔ∏è TEAM ACTIVITY 4:\u003c/strong\u003e\u003c/div\u003e \n",
                "\n",
                "Let's focus on introducing new features to see if our model performs better. After talking to our client for four hours and doing some some thought, we concluded that the mean predicted market value should be:\n",
                "\n",
                "$$\\hat{y} = \\beta_0 + \\beta_1\\cdot \\text{fpl_points} + \\beta_2\\cdot\\text{age} + \\beta_3\\cdot\\text{age}^2 + \\beta_4\\cdot \\text{new_signing} +\\beta_5\\cdot \\text{big_club} + \\beta_6\\cdot \\text{position_cat} \\\\ + \\beta_7\\cdot \\text{age_cat} + \\beta_8\\cdot \\text{page_views}\\times \\text{fpl_points}$$\n",
                "\n",
                "We're including a 2nd degree polynomial in age because we expect pay to increase as a player gains experience, but then decrease as they continue aging. We also include an interaction term between `page_views` and `fpl_points`.\n",
                "\n",
                "1. Build a design matrix function and fit this model to the training data. How good is the overall model?\n",
                "2. Interpret the regression model. What is the meaning of the coefficient for:\n",
                "    - age and age$^2$\n",
                "    - big_club\n",
                "2. What should a player do in order to improve their market value? How many page views should a player go get to increase their market value by 10?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load a fresh train and test set.\n",
                "train_data = pd.read_csv(\"train_data.csv\")\n",
                "test_data = pd.read_csv(\"test_data.csv\")\n",
                "train_data.head(2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code here\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check\n",
                "print(f'LR train R^2: {model.score(X_train, y_train):.3f}')\n",
                "print(f'LR test R^2: {model.score(X_test, y_test):.3f}')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Conceptual questions\n",
                "\n",
                "1. The model is reasonably good. We're capturing about 76% of the variation in market values, and the test set confirms that we're not overfitting too badly.\n",
                "2. Look at the coefficients, depends upon your split..\n",
                "3. Linear regression on non-experimental data can't determine causation, so we can't prove that a given relationship runs in the direction we might think. For instance, doing whatever it takes to get more page views probably doesn't meaningfully increase market value; it's likely the causation runs in the other direction and great players get more views. Even so, we can use page views to help us tell who is a great player and thus likely to be paid well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "agecoef = float(coefs.loc['age'].values)\n",
                "age2coef = float(coefs.loc['age_sq'].values)\n",
                "agecoef, age2coef"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "x_vals = np.linspace(-100,100,1000)\n",
                "y_vals = agecoef*x_vals +age2coef*x_vals**2\n",
                "plt.plot(x_vals, y_vals)\n",
                "plt.title(\"Effect of Age on Player Market value\")\n",
                "plt.xlabel(\"Age\")\n",
                "plt.ylabel(\"Contribution to Predicted Market Value\")\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Conceptual questions\n",
                "\n",
                "1. If our model does not have a constant, we must include all four dummy variable columns. If we drop one, we're not modeling any effect of being in that category, and effectively assuming the dropped category's effect is 0.\n",
                "2. Being in position 2 (instead of position 1) has an impact between -1.54 and +2.38 on a player's market value. Since we're using an intercept, the dropped category becomes the baseline and the effect of any dummy variable is the effect of being in that category instead of the baseline category."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### END OF LAB 04"
            ]
        }
    ]
}
