{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "\n",
    "Exercise: Hyperparameter tuning\n",
    "\n",
    "## Description :\n",
    "\n",
    "### Tuning the hyperparameters\n",
    "\n",
    "Random Forests perform very well out-of-the-box, with the pre-set hyperparameters in sklearn. Some of the tunable parameters are:\n",
    "\n",
    "- The number of trees in the forest: n_estimators, int, default=100\n",
    "- The complexity of each tree: stop when a leaf has <= min_samples_leaf samples \n",
    "- The sampling scheme: number of features to consider at any given split: max_features {“auto”, “sqrt”, “log2”}, int or float, default=”auto”.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- Read the datafile diabetes.csv as a Pandas data frame.\n",
    "- Assign the predictor and response variable as mentioned in the scaffold.\n",
    "- Split the data into train and validation sets.\n",
    "- Define a vanilla Random Forest and fit the model on the entire data.\n",
    "- For various hyper parameters of the model, define different Random Forest models and train on the data.\n",
    "- Compare the results with each model.\n",
    "\n",
    "## Hints: \n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\">RandomForestClassifier()</a>\n",
    "Defines the RandomForestClassifier and includes more details on the definition and range of values for its tunable parameters.\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba\" target=\"_blank\">model.predict_proba(X)</a>\n",
    "Predict class probabilities for X\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\" target=\"_blank\">roc_auc(y_test, y_proba)</a>\n",
    "Calculates the area under the receiver operating curve (AUC).\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\" target=\"_blank\">GridSearchCV()</a>\n",
    "Performes exhaustive search over specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset and take a quick look\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the predictor and response variables.\n",
    "# Outcome is the response and all the other columns are the predictors\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df['Outcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility of results\n",
    "seed = 0\n",
    "\n",
    "# Split the data into train and test sets with the mentioned seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanila random forest\n",
    "\n",
    "Start by training a Random Forest Classifier using the default parameters and calculate the Receiver Operating Characteristic Area Under the Curve (ROC AUC). As we know, this metric is better than accuracy for a classification problem, since it covers the case of an imbalanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_vanilla) ### \n",
    "\n",
    "# Define a Random Forest classifier with randon_state = seed\n",
    "vanilla_rf = ___ \n",
    "\n",
    "# Fit the model on the entire data\n",
    "vanilla_rf.fit(___, ___);\n",
    "\n",
    "# Calculate AUC/ROC on the test set\n",
    "y_proba = ___[:, 1] \n",
    "auc = np.round(roc_auc_score(y_test, y_proba),2)\n",
    "print(f'Plain RF AUC on test set:{auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples and features\n",
    "num_features = X_train.shape[1]\n",
    "num_samples = X_train.shape[0]\n",
    "num_samples, num_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Number of trees, `num_iterators`, default = 100\n",
    "\n",
    "The number of trees needs to be large enough for the $oob$ error to stabilize in its lowest possible value. Plot the $oob$ error of a random forest as a function of the number of trees. Trees in a RF are called `estimators`. A good start is 10 times the number of features, however, adjusting other hyperparameters will influence the optimum number of trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import OrderedDict\n",
    "clf = RandomForestClassifier(warm_start=True, \n",
    "                               oob_score=True,\n",
    "                               min_samples_leaf=40,\n",
    "                               max_depth = 10,\n",
    "                               random_state=seed)\n",
    "\n",
    "error_rate = {}\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 150\n",
    "max_estimators = 500\n",
    "\n",
    "for i in range(min_estimators, max_estimators + 1):\n",
    "    clf.set_params(n_estimators=i) \n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Record the OOB error for each `n_estimators=i` setting.\n",
    "    oob_error = 1 - clf.oob_score_\n",
    "    error_rate[i] = oob_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "# OOB error rate = num_missclassified/total observations (%)\\\n",
    "xs = []\n",
    "ys = []\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs.append(label)\n",
    "    ys.append(clf_err)   \n",
    "plt.plot(xs, ys)\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `min_samples_leaf`, default = 1\n",
    "\n",
    "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression. We will plot various values of the `min_samples_leaf` with `num_iterators`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import OrderedDict\n",
    "ensemble_clfs = [\n",
    "    (1,\n",
    "        RandomForestClassifier(warm_start=True, \n",
    "                               min_samples_leaf=1,\n",
    "                               oob_score=True,\n",
    "                               max_depth = 10,\n",
    "                               random_state=seed)),\n",
    "    (5,\n",
    "        RandomForestClassifier(warm_start=True, \n",
    "                               min_samples_leaf=5,\n",
    "                               oob_score=True,\n",
    "                               max_depth = 10,\n",
    "                               random_state=seed))\n",
    "]\n",
    "\n",
    "# Map a label (the value of `min_samples_leaf`) to a list of (model, oob error) tuples.\n",
    "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "min_estimators = 80\n",
    "max_estimators = 500\n",
    "\n",
    "for label, clf in ensemble_clfs:\n",
    "    for i in range(min_estimators, max_estimators + 1):\n",
    "        clf.set_params(n_estimators=i) \n",
    "        clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "        # Record the OOB error for each model. Error is 1 - oob_score\n",
    "        # oob_score: score of the training dataset obtained using an \n",
    "        # out-of-bag estimate.\n",
    "        # OOB error rate is % of num_missclassified/total observations\n",
    "        oob_error = 1 - clf.oob_score_\n",
    "        error_rate[label].append((i, oob_error))\n",
    "\n",
    "for label, clf_err in error_rate.items():\n",
    "    xs, ys = zip(*clf_err)\n",
    "    plt.plot(xs, ys, label=f'min_samples_leaf={label}')\n",
    "\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 100\n",
    "best_num_estimators = 0\n",
    "for label, clf_err in error_rate.items():\n",
    "    num_estimators, error = min(clf_err, key=lambda n: (n[1], -n[0]))\n",
    "    if error<err: err=error; best_num_estimators = num_estimators; best_leaf = label\n",
    "\n",
    "print(f'Optimum num of estimators: {best_num_estimators} \\nmin_samples_leaf: {best_leaf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train the Random Forest Classifier using the new values for the parameters and calculate the AUC/ROC. Include another parameter, the `max_features`, the number of features to consider when looking for the best split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_estimators) ### \n",
    "estimators_rf = RandomForestClassifier(n_estimators= best_num_estimators,\n",
    "                                    random_state=seed,\n",
    "                                    oob_score=True,\n",
    "                                    min_samples_leaf=best_leaf,\n",
    "                                    max_features='sqrt') \n",
    "\n",
    "# Fit the model on the entire data\n",
    "estimators_rf.fit(X_train, y_train);\n",
    "\n",
    "# Calculate AUC/ROC on the test set\n",
    "y_proba = ___[:, 1]\n",
    "estimators_auc = np.round(roc_auc_score(y_test, y_proba),2)\n",
    "print(f'Educated RF AUC on test set:{estimators_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_rf.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Performing a cross-validation search\n",
    "\n",
    "After we have some idea of the range of optimum values for the number of trees and maybe a couple of other parameters, and have enough computing power, you may perform an exhaustive search over other parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "do_grid_search = True\n",
    "\n",
    "if do_grid_search:\n",
    "    rf = RandomForestClassifier(n_jobs=-1,\n",
    "                               n_estimators= best_num_estimators,\n",
    "                               oob_score=True,\n",
    "                               max_features = 'sqrt',\n",
    "                               min_samples_leaf=best_leaf,\n",
    "                               random_state=seed).fit(X_train,y_train)\n",
    "\n",
    "    param_grid = {\n",
    "        'min_samples_split': [2,5,None]}\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc'}\n",
    "    \n",
    "    grid_search = GridSearchCV(rf, \n",
    "                               param_grid, \n",
    "                               scoring=scoring, \n",
    "                               refit='AUC', \n",
    "                               return_train_score=True, \n",
    "                               n_jobs=-1)\n",
    "    \n",
    "    results = grid_search.fit(X_train, y_train)\n",
    "    print(results.best_estimator_.get_params())\n",
    "    best_rf = results.best_estimator_\n",
    "    # Calculate AUC/ROC\n",
    "    y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "    auc = np.round(roc_auc_score(y_test, y_proba),2)\n",
    "    print(f'GridSearchCV RF AUC on test set:{auc}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
